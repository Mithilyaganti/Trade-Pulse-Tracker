services:
  # Zookeeper - Required for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - trade-pulse-network
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka - Message queuing system for decoupled communication
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - trade-pulse-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions --bootstrap-server localhost:9092",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL - Stores current price snapshots with low-latency access
  postgres:
    image: postgres:15-alpine
    hostname: postgres
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: tradepulse
      POSTGRES_USER: tradepulse
      POSTGRES_PASSWORD: tradepulse123
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - trade-pulse-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tradepulse -d tradepulse"]
      interval: 30s
      timeout: 10s
      retries: 3

  # InfluxDB - Time-series database optimized for latency metrics
  influxdb:
    image: influxdb:2.7-alpine
    hostname: influxdb
    container_name: influxdb
    ports:
      - "8086:8086"
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: adminpassword
      DOCKER_INFLUXDB_INIT_ORG: tradepulse
      DOCKER_INFLUXDB_INIT_BUCKET: metrics
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: tradepulse-super-secret-auth-token
    volumes:
      - influxdb_data:/var/lib/influxdb2
      - influxdb_config:/etc/influxdb2
    networks:
      - trade-pulse-network
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana - Visualizes latency metrics with customizable dashboards
  grafana:
    image: grafana/grafana:10.0.0
    hostname: grafana
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - trade-pulse-network
    depends_on:
      influxdb:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring Service - Phase 2: Standalone HTTP endpoint monitor
  monitoring-service:
    build:
      context: ./packages/monitoring-service
      dockerfile: Dockerfile
      network: host
    hostname: monitoring-service
    container_name: monitoring-service
    environment:
      # InfluxDB Configuration
      INFLUX_URL: http://influxdb:8086
      INFLUX_TOKEN: tradepulse-super-secret-auth-token
      INFLUX_ORG: tradepulse
      INFLUX_BUCKET: metrics

      # Monitoring Configuration
      PROBE_INTERVAL: "*/30 * * * * *" # Every 30 seconds

      # Configure targets to monitor - now includes ingestor and snapshot services
      TARGETS: "http://ingestor:9090/metrics,http://snapshot-service:9091/metrics,http://httpbin.org/delay/1,http://httpbin.org/status/200"
    networks:
      - trade-pulse-network
    depends_on:
      influxdb:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test:
        ["CMD", "node", "-e", "console.log('Monitoring service health check')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Tick Generator - Phase 3: Financial price tick generator
  tick-generator:
    build:
      context: ./packages/tick-generator
      dockerfile: Dockerfile
      network: host
    hostname: tick-generator
    container_name: tick-generator
    networks:
      - trade-pulse-network
    volumes:
      # Mount additional CSV data files if needed
      - ./packages/tick-generator/data:/app/data
    restart: "no" # Don't auto-restart, let it complete its task
    profiles:
      - tick-generator # Optional profile to start only when needed
    # Default configuration - can be overridden via docker-compose override
    command: >
      sh -c "echo 'Tick Generator is ready. Use docker-compose run commands to start specific data sources:' &&
             echo '  CSV Replay: docker-compose run --rm tick-generator node dist/index.js --source=csv --file=/app/data/AAPL.csv --host=ingestor --port=8080' &&
             echo '  Binance Relay: docker-compose run --rm tick-generator node dist/index.js --source=binance --symbols=BTCUSDT,ETHUSDT --host=ingestor --port=8080' &&
             echo 'Sleeping for manual activation...' &&
             sleep infinity"

  # Ingestor Service - Phase 4: TCP price tick ingestor with Kafka publishing
  ingestor:
    build:
      context: ./packages/ingestor
      dockerfile: Dockerfile
      network: host
    hostname: ingestor
    container_name: ingestor
    ports:
      - "8080:8080" # TCP server for receiving price ticks
      - "9090:9090" # Prometheus metrics endpoint
    environment:
      # TCP Server Configuration
      TCP_HOST: "0.0.0.0"
      TCP_PORT: "8080"
      TCP_MAX_CONNECTIONS: "100"
      TCP_KEEP_ALIVE: "true"
      TCP_KEEP_ALIVE_DELAY: "30000"

      # Kafka Configuration
      KAFKA_BROKERS: "kafka:29092"
      KAFKA_TOPIC: "price-ticks"
      KAFKA_CLIENT_ID: "trade-pulse-ingestor"
      KAFKA_ACKS: "1"
      KAFKA_RETRIES: "3"
      KAFKA_COMPRESSION: "gzip"
      KAFKA_BATCH_SIZE: "16384"
      KAFKA_LINGER_MS: "10"

      # Metrics Configuration
      METRICS_ENABLED: "true"
      METRICS_PORT: "9090"
      METRICS_PATH: "/metrics"

      # Validation Configuration
      VALIDATION_STRICT_MODE: "false"
      VALIDATION_MAX_PRICE_DEVIATION: "0.1" # 10%
      VALIDATION_MAX_TIMESTAMP_AGE: "300000" # 5 minutes
    networks:
      - trade-pulse-network
    depends_on:
      kafka:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'node -e "const http = require(''http''); const options = { host: ''localhost'', port: 9090, path: ''/metrics'', timeout: 5000 }; const req = http.request(options, (res) => { if (res.statusCode === 200) { console.log(''Health check: OK''); process.exit(0); } else { console.log(''Health check: Failed''); process.exit(1); } }); req.on(''error'', () => { console.log(''Health check: Error''); process.exit(1); }); req.end();" || exit 1',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Snapshot Service - Phase 5: Maintains current price state and serves clients
  snapshot-service:
    build:
      context: ./packages/snapshot-service
      dockerfile: Dockerfile
      network: host
    hostname: snapshot-service
    container_name: snapshot-service
    ports:
      - "3001:3001" # REST API
      - "3002:3002" # WebSocket server
      - "9091:9091" # Prometheus metrics
    environment:
      # Kafka Configuration
      KAFKA_BROKERS: "kafka:29092"
      KAFKA_TOPIC: "price-ticks"
      KAFKA_GROUP_ID: "snapshot-service-group"
      KAFKA_CLIENT_ID: "trade-pulse-snapshot-service"

      # PostgreSQL Configuration
      POSTGRES_HOST: "postgres"
      POSTGRES_PORT: "5432"
      POSTGRES_DATABASE: "tradepulse"
      POSTGRES_USER: "tradepulse"
      POSTGRES_PASSWORD: "tradepulse123"
      POSTGRES_MAX_CONNECTIONS: "20"

      # REST API Configuration
      REST_API_PORT: "3001"
      REST_API_HOST: "0.0.0.0"

      # WebSocket Configuration
      WEBSOCKET_PORT: "3002"
      WEBSOCKET_HOST: "0.0.0.0"

      # Metrics Configuration
      METRICS_ENABLED: "true"
      METRICS_PORT: "9091"
      METRICS_PATH: "/metrics"

      # Performance Configuration
      BATCH_SIZE: "50"
      FLUSH_INTERVAL: "1000" # 1 second
      MAX_RETRIES: "3"

      # Development mode for detailed logging
      NODE_ENV: "development"
    networks:
      - trade-pulse-network
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      ingestor:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'node -e "const http = require(''http''); const options = { host: ''localhost'', port: 9091, path: ''/health'', timeout: 5000 }; const req = http.request(options, (res) => { if (res.statusCode === 200) { console.log(''Health check: OK''); process.exit(0); } else { console.log(''Health check: Failed''); process.exit(1); } }); req.on(''error'', () => { console.log(''Health check: Error''); process.exit(1); }); req.end();" || exit 1',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

networks:
  trade-pulse-network:
    driver: bridge
    name: trade-pulse-network

volumes:
  postgres_data:
    name: trade-pulse-postgres-data
  influxdb_data:
    name: trade-pulse-influxdb-data
  influxdb_config:
    name: trade-pulse-influxdb-config
  grafana_data:
    name: trade-pulse-grafana-data
